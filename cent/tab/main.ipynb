{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "from matplotlib import pyplot as plt\n",
    "# %matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('../data/cbtc/csv/train.csv')\n",
    "train_data = pd.read_csv('../../data/cbtc/csv/new/1.hcz2cq/train.csv')\n",
    "test_data = pd.read_csv('../../data/cbtc/csv/new/1.hcz2cq/test.csv')\n",
    "\n",
    "# FEATURES = ['brake','target','speed','slope']\n",
    "FEATURES = ['brake','target','speed','slope']\n",
    "# LABEL = ['acc']\n",
    "LABEL = ['acc']\n",
    "\n",
    "train_features = train_data.loc[:, FEATURES]\n",
    "train_label = train_data.loc[:, LABEL]\n",
    "\n",
    "test_features = test_data.loc[:, FEATURES]\n",
    "# test_labels = test_data.loc[1:, ['acc']]\n",
    "test_label = test_data.loc[:, LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# # 输入标准化\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# train_features = StandardScaler().fit_transform(train_features)\n",
    "# test_features = StandardScaler().fit_transform(test_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# train_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_handler(x_input):\n",
    "    x_array = np.array(x_input)\n",
    "    x_tensor = th.tensor(x_array)\n",
    "\n",
    "    return x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = data_handler(train_features)\n",
    "train_label = data_handler(train_label)\n",
    "\n",
    "test_features = data_handler(test_features)\n",
    "test_label = data_handler(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epoch_nums = 160\n",
    "learn_rate = 0.0001\n",
    "wgt_dcy = 0.1\n",
    "# 实际速度放大100倍, loss除以1e4\n",
    "multiple = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler(Dataset):\n",
    "    def __init__(self,x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx,:], self.y[idx]\n",
    "\n",
    "# train_dataset = DatasetHandler(train_features, train_label)\n",
    "# train_dataset = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_dataset = DatasetHandler(train_features, train_label)\n",
    "train_dataset = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = DatasetHandler(test_features, test_label)\n",
    "test_dataset = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabTransformer(\n",
    "    categories = (2500, 2500, 2500), # 离散\n",
    "    num_continuous = 1, # 连续\n",
    "    dim = 32, # dimension, paper set at 32\n",
    "    dim_out = 1, # 输出维度\n",
    "    depth = 6, # depth, paper recommended 6\n",
    "    heads = 8, # heads, paper recommends 8\n",
    "    attn_dropout = 0.1, # post-attention dropout\n",
    "    ff_dropout = 0.1, # feed forward dropout\n",
    "    mlp_hidden_mults = (4, 2), # relative multiples of each hidden dimension\n",
    "    mlp_act = nn.ReLU(), # activation for final mlp, defaults to relu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = nn.MSELoss(reduction='mean')\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=learn_rate, weight_decay=wgt_dcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# loss_all = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epoch_nums):\n",
    "    loss_all = 0\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in enumerate(train_dataset, 0):\n",
    "        features, label = data\n",
    "            \n",
    "        features_spt = th.split(features, 3, dim=1) # 拆分输入\n",
    "        features_ctg = features_spt[0] # 离散变量\n",
    "        features_ctn = features_spt[1].to(th.float32) # 坡度\n",
    "            \n",
    "        label = label.to(th.float32) # 加速度\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        y_pre = model(features_ctg, features_ctn)\n",
    "        loss = cost(y_pre, label)\n",
    "        loss_all += loss\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_all /= len(train_dataset)*multiple*multiple\n",
    "    print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch + 1, epoch_nums, loss_all))\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def valid(models, dataset):\n",
    "    models.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for i, data in enumerate(dataset, 0):\n",
    "            # 得到数据和标签\n",
    "            features, label = data\n",
    "\n",
    "            feature_spt = th.split(features, 3, dim=1) # 拆分输入\n",
    "            feature_ctg = feature_spt[0] # 离散变量\n",
    "            feature_ctn = feature_spt[1].to(th.float32) # 坡度\n",
    "            # feature_ctg, feature_ctn = split(features)\n",
    "            label = label.to(th.float32)\n",
    "\n",
    "            # 预测\n",
    "            pre = models(feature_ctg, feature_ctn)\n",
    "            total_loss += cost(pre, label).item()\n",
    "            # print(i)\n",
    "\n",
    "    total_loss /= len(dataset)*multiple*multiple\n",
    "\n",
    "    print(\"valid loss = {:.6f}\".format(total_loss))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid(model, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_input):\n",
    "    model.eval()\n",
    "    feature_spt = th.split(test_input, 3, dim=1)\n",
    "    feature_ctg = feature_spt[0]\n",
    "    feature_ctn = feature_spt[1].to(th.float32)\n",
    "\n",
    "    pred_data = model(feature_ctg, feature_ctn)\n",
    "    return pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = predict(test_features)\n",
    "test_pred = test_pred.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = test_pred # 预测加速度\n",
    "y_test = test_label # 实际加速度\n",
    "\n",
    "# 画出加速度-时间曲线\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.title(\"Train Acceleration\")\n",
    "plt.xlabel('Time / s')\n",
    "plt.ylabel('Acceleration m/s')\n",
    "\n",
    "data_len = len(y_test) - 1\n",
    "x = 0.2 * np.linspace(0, data_len, data_len+1, endpoint=True)\n",
    "plt.plot(x, y_test /100, 'b', linewidth=1, label=\"test acceleration\")\n",
    "plt.plot(x, y_pred /100, 'r', linewidth=1, label=\"pred acceleration\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# test = test_data.iloc[:, 2] # test speed\n",
    "test = test_data.loc[:, ['speed']] # test speed\n",
    "pred = np.zeros(len(test)) # pred speed\n",
    "\n",
    "for idx in range(len(test)):\n",
    "    pred[idx] = sum(test_pred[0:idx]) / 5\n",
    "\n",
    "# 画出速度-时间曲线\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.title(\"Train Speed\")\n",
    "plt.xlabel('Time / s')\n",
    "plt.ylabel('Speed m/s')\n",
    "\n",
    "data_len = len(test) - 1\n",
    "x = 0.2 * np.linspace(0, data_len, data_len+1, endpoint=True)\n",
    "\n",
    "plt.plot(x, test / 100, 'b', linewidth=1, label=\"test speed\")\n",
    "plt.plot(x, pred / 100, 'r', linewidth=1, label=\"pred speed\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
